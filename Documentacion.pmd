# Data Driven Security

## Introducción

## Recolección de los Datos
Se ha recogido datos de distintas fuentes para realizar un estudio sobre IPs maliciosas en blacklists.
La información tratada se ha recogido de las siguientes fuentes:

[Listas IPs maliciosas](https://github.com/firehol/blocklist-ipsets)  
[Base de datos de geolocalización](https://dev.maxmind.com/geoip/geoip2/geolite2/)  
[Datos de población](https://data.worldbank.org/indicator/SP.POP.TOTL)

Los datos obtenidos, se han parseado y limpiado para poder sacar la información relevante.
De firehol se ha extraido la siguiente información : IP, Categoría, Quien matiene la lista donde aparece dicha ip y 
fecha de la lista.
De maxmind hemos obtenido la geolocalización de cada ip mediante su API.

## Definición de funciones
A continuación definimos las funciones utilitzadas para el tratamiento de datos, hay que tener en cuenta que la función
*getdataframe* tiene bastante coste temporal, por ello, es preferible guardar el dataframe en disco para luego cargarlo.

```python, term=True
    import os
    import glob
    import pandas
    import geoip2.database as db
    import datetime
    
    def getdataframe(source,dest = ""):
        files = glob.glob(os.path.join(source,"*.ipset"))
        dftotal = pandas.DataFrame(columns=["IP","Category","Maintainer","Country","Date"])
        reader = db.Reader(r"./GeoLite2-Country_20191210/GeoLite2-Country.mmdb")
        for f in files:
            ips = []
            countrylist = []
            cat = ""
            main = ""
            date = ""
            df = pandas.DataFrame(columns=["IP","Category","Maintainer","Country","Date"])
            aux = open(f,"r")
            content = aux.readlines()
            aux.close()
            for l in  content:
                if "Category" in l:
                    cat = str(l.split(":")[-1]).strip()
                elif "Maintainer" in l:
                    main = str(l.split(":")[-1]).strip().replace("/","")
                elif "#" not in l:
                    ips.append(str(l).strip())
                elif "This File Date" in l:
                    date = str(l.split(" : ")[-1]).strip().replace("  "," ")
                    try:
                        date = str(datetime.datetime.strptime(date, "%a %b %d %H:%M:%S UTC %Y"))
                    except:
                        print(str(l))
            df["IP"] = ips
            df["Category"] = [cat]*len(ips)
            df["Maintainer"] = [main]*len(ips)
            df["Date"] = [date]*len(ips)
            for ip in df.IP.values:
                try:
                    c = reader.country(ip).country.names["en"]
                except:
                    c = ''
                countrylist.append(c)
            df["Country"] = countrylist
            dftotal = dftotal.append(df, ignore_index = True)
        if dest != "" and not os.path.exists(dest):
            dftotal.drop(columns=dftotal.columns[0]).to_csv(dest)
        return dftotal.drop(columns=dftotal.columns[0])

    def dropduplicates(df,groupcolumns):
        aux = df
        aux["Occurrence"] = df.groupby(groupcolumns).cumcount() + 1
        return aux.drop_duplicates(subset = groupcolumns, keep = "last")
```

## Datos limpios
Con lo mencionado se ha generado el siguiente dataframe con toda la información limpia, con la primera linea generamos
de nuevo el dataframe, con la segunda, cargamos uno preguardado.

```python, term=True
    #df = getdataframe(r"C:\Users\Marc\Desktop\pers\datadriven\Practica\blocklist-ipsets-master")
    df = pandas.read_csv(r"C:\Users\Marc\Desktop\pers\datadriven\Practica\brutedataframe_country_date.csv")
    df
```

Por último con la información de worldbank hemos generado un dataframe que contiene información relevante por país.

```python, term=True
    df1 = pandas.read_csv(r"C:\Users\Marc\Desktop\pers\datadriven\Practica\PopulationData\API_SP.POP.TOTL_DS2_en_csv_v2_566132.csv")
    df1
```

## Observaciones con datos de un día
Inicialmente se ha esbozado un primer estudio solo con los datos de un solo día obtenidos de firehol.
Con ello se quiere realizar observaciones a pequeña escara antes de pasar a grandes conjuntos de datos.

### Distribución de ips maliciosas por categoria
Se ha estudiado como se reparten las ips maliciosas en las distintas categorías definidas por firehol. 

A continuación se ha transformado la información ya limpia para representar correctamente lo que se quería observar.
Para ello se ha usado la información recopilada en el datafrme df.
Dado que df contenía ips repetidas en la misma categoría, se han llevado a cabo distintos pasos para agrupar 
la información de forma conveniente.
 
* En primer lugar, se ha agrupado toda la información del dataframe por IP/categoría y a continguación se han
eliminado los duplicados.

```python, term=True
    df2 = dropduplicates(df,["IP","Category"])
    df2
```

* Por último, se ha pivotado la información para quedara una tabla representado lo que se quería observar.

        (tabla df2)

Una vez tratados los datos podemos observar la siguiente distribuión según categoría:

    (barpolt)

    (donutplot)

### Indice de peligrosidad por país
Los datos obtenidos se han utilitzado para observar y calcular un indice de peligrosidad por país.
Para conseguir dicho indice se han usado los datos de df y df3. Para poder representar la información correctamente,
se ha generado un nuevo dataframe que contiene el país con su indice calculado en base a
 **nº IPs maliciosas / Población**.
 
    (tabla df5)

### Distribución de categorías por país

## Observaciones temporales (Datos varios días)

Evolución temporal de ips por categoria

Evolución temporal de países según peligrosidad

Evolución temporal de categorías por país 

## Predicciónes

Predecir la posibilidad que una IP se vaya a incluir en blacklist y en que categoria se incluiria.

### Datos relevantes para Predecir
Para poder entrenar un modelo de predicción hay que disponer de suficientes datos con atributos releventes
diferenciados. De este modo y en base a los atributos se puede realizar la predicción.

* País de origen
* Veces en blacklist días distintos
* Veces en blacklist mismo día
* Tiempo en uso (mismo propietario)
* Categoría en blacklist
* Tiempo en blacklist

## Tiempos de ejecucion
* Parser -> 617.61s 878.29s
* Drop duplicates -> 9.66s
* spread -> 8.47s